{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:44:54.957523Z",
     "iopub.status.busy": "2022-04-08T17:44:54.957218Z",
     "iopub.status.idle": "2022-04-08T17:44:56.31368Z",
     "shell.execute_reply": "2022-04-08T17:44:56.312951Z",
     "shell.execute_reply.started": "2022-04-08T17:44:54.957473Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from nltk import ngrams\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:06:41.341814Z",
     "iopub.status.busy": "2022-04-08T18:06:41.341537Z",
     "iopub.status.idle": "2022-04-08T18:06:41.351474Z",
     "shell.execute_reply": "2022-04-08T18:06:41.350572Z",
     "shell.execute_reply.started": "2022-04-08T18:06:41.34178Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "hashtag_regex = r\"#(\\w+)\"\n",
    "mention_regex = r\"\\B@(?!(?:[a-z0-9.]*_){2})(?!(?:[a-z0-9_]*\\.){2})[._a-z0-9]{3,24}\\b\"\n",
    "start = ['<pad>','<pad>','<pad>','<pad>']\n",
    "# end = np.array(['<pad>','<pad>','<pad>'])\n",
    "punc = [',', '.', '!', ';', '?']\n",
    "def tokenizer(messages):\n",
    "    tokenized_data = []\n",
    "#     for messages in data:\n",
    "    messages = messages.lower()\n",
    "#         messages = re.sub(url_regex,'<URL>',messages)\n",
    "#         messages = re.sub(hashtag_regex,'<HASHTAG>',messages)\n",
    "#         messages = re.sub(mention_regex, '<MENTION>',messages)\n",
    "#         newmessage = ''\n",
    "#         for i in range(len(messages)):\n",
    "#             if re.match(r'[^\\w\\s]', messages[i]) and messages[i]!='<' and messages[i]!='>':\n",
    "#                 newmessage+=' '+messages[i]+' '\n",
    "#             else:\n",
    "#                 newmessage+=messages[i]\n",
    "\n",
    "#         if newmessage == '':\n",
    "#             continue\n",
    "    messages = re.sub(r'[^\\w\\s]','',messages)\n",
    "    words = re.split('\\s|\\t|\\n', messages)\n",
    "#         words = words[words!='']\n",
    "#         if len(words)==0:\n",
    "#             continue\n",
    "#         m = len(words)\n",
    "#         for i  in range(m):\n",
    "#             if len(words[i])!=1:\n",
    "#                 continue\n",
    "#             if words[i] in punc and words[i] not in ['s','e','<URL>','<HASHTAG>','<MENTION>']:\n",
    "#                 words[i] = re.sub(r'[^\\w\\s]','',words[i])\n",
    "#         words = words[words!='']\n",
    "#         for wo in words:\n",
    "#             tokenized_data.append(wo)\n",
    "        #tokenized_data.append(np.concatenate((start, words, end)))\n",
    "    return start+words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T17:59:14.419812Z",
     "iopub.status.busy": "2022-04-08T17:59:14.419561Z",
     "iopub.status.idle": "2022-04-08T17:59:14.426536Z",
     "shell.execute_reply": "2022-04-08T17:59:14.425738Z",
     "shell.execute_reply.started": "2022-04-08T17:59:14.419782Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus(path):\n",
    "    df = []\n",
    "    si = 0\n",
    "    tot = 0\n",
    "    with open(path) as infile:\n",
    "        for ob in infile:\n",
    "            flag = rand.randint(0,100)\n",
    "            tot+=1\n",
    "            if flag>2:\n",
    "                continue\n",
    "            si+=1\n",
    "            # if si%10000 == 0:\n",
    "            #     print(si,tot)\n",
    "            obj = json.loads(ob)\n",
    "            cur = obj['reviewText']\n",
    "            df.append(tokenizer(cur))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:07:17.846376Z",
     "iopub.status.busy": "2022-04-08T18:07:17.846123Z",
     "iopub.status.idle": "2022-04-08T18:07:17.861677Z",
     "shell.execute_reply": "2022-04-08T18:07:17.860781Z",
     "shell.execute_reply.started": "2022-04-08T18:07:17.846347Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    \"\"\" Function to read input data\n",
    "    Args:\n",
    "        path (string): the parent path of the folder containing the input text files\n",
    "    Returns:\n",
    "        string: The complete text read from input files appended in a single string.\n",
    "    \"\"\"\n",
    "    text = ' '\n",
    "    f = open(path, 'r')\n",
    "    text = f.readlines()\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\" Function for basic cleaning and pre-processing of input text\n",
    "    Args:\n",
    "        text (string): raw input text\n",
    "    Returns:\n",
    "        string: cleaned text\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in text:\n",
    "        data += tokenizer(line)\n",
    "    return data\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r\"'s\\b\", \"\", text)\n",
    "#     text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "#     text = ' '.join([word for word in text.split() if len(word) >= 3]).strip()\n",
    "\n",
    "#     return text\n",
    "\n",
    "\n",
    "def prepare_text(data, n):\n",
    "    \"\"\" Function to prepare text in sequence of ngrams\n",
    "    Args:\n",
    "        text (string): complete input text\n",
    "    Returns:\n",
    "        list : a list of text sequence with 31 characters each\n",
    "    \"\"\"\n",
    "    n_grams = []\n",
    "    for i in range(len(data)-n):\n",
    "        n_grams.append(data[i:i+n])\n",
    "    return n_grams\n",
    "\n",
    "def create_data(data, word_id, id_word):\n",
    "    \"\"\" Function to encode the character sequence into number sequence\n",
    "    Args:\n",
    "        text (string): cleaned text\n",
    "        sequence (list): character sequence list\n",
    "    Returns:\n",
    "        dict: dictionary mapping of all unique input charcters to integers\n",
    "        list: number encoded charachter sequences\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in data:\n",
    "        inp = []\n",
    "        for j in range(4):\n",
    "            inp.append(word_id[i[j]])\n",
    "        y.append(word_id[i[4]])\n",
    "        x.append(inp)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x,y\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def split_data(mapping, encoded_sequence):\n",
    "    \"\"\" Function to split the prepared data in train and test\n",
    "    Args:\n",
    "        mapping (dict): dictionary mapping of all unique input charcters to integers\n",
    "        encoded_sequence (list): number encoded charachter sequences\n",
    "    Returns:\n",
    "        numpy array : train and test split numpy arrays\n",
    "    \"\"\"\n",
    "\n",
    "    encoded_sequence_ = np.array(encoded_sequence)\n",
    "    X, y = encoded_sequence_[:, :-1], encoded_sequence_[:, -1]\n",
    "    y = to_categorical(y, num_classes=len(mapping))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def create_vocab(data, threshold =  5):\n",
    "    freq = {}\n",
    "    for i in data:\n",
    "        if i not in freq.keys():\n",
    "            freq[i] = 0\n",
    "        freq[i]+=1\n",
    "    for i in range(len(data)):\n",
    "        if freq[data[i]] <= threshold:\n",
    "            data[i] = '<UNKNOWN>'\n",
    "    word_id = {}\n",
    "    id_word = {}\n",
    "    cur = 0\n",
    "    for i in data:\n",
    "        if i not in word_id.keys():\n",
    "            word_id[i] = cur\n",
    "            id_word[cur] = i\n",
    "            cur+=1\n",
    "    return data, word_id, id_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:07:22.96724Z",
     "iopub.status.busy": "2022-04-08T18:07:22.965939Z",
     "iopub.status.idle": "2022-04-08T18:07:22.991079Z",
     "shell.execute_reply": "2022-04-08T18:07:22.990204Z",
     "shell.execute_reply.started": "2022-04-08T18:07:22.967193Z"
    }
   },
   "outputs": [],
   "source": [
    "text = read_text('../input/dataset/train.europarl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:07:26.6018Z",
     "iopub.status.busy": "2022-04-08T18:07:26.601505Z",
     "iopub.status.idle": "2022-04-08T18:07:26.99277Z",
     "shell.execute_reply": "2022-04-08T18:07:26.992016Z",
     "shell.execute_reply.started": "2022-04-08T18:07:26.60177Z"
    }
   },
   "outputs": [],
   "source": [
    "data = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:08:00.468766Z",
     "iopub.status.busy": "2022-04-08T18:08:00.467995Z",
     "iopub.status.idle": "2022-04-08T18:08:00.815456Z",
     "shell.execute_reply": "2022-04-08T18:08:00.814732Z",
     "shell.execute_reply.started": "2022-04-08T18:08:00.468708Z"
    }
   },
   "outputs": [],
   "source": [
    "data, word_id, id_word = create_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:08:49.544412Z",
     "iopub.status.busy": "2022-04-08T18:08:49.543871Z",
     "iopub.status.idle": "2022-04-08T18:08:50.24106Z",
     "shell.execute_reply": "2022-04-08T18:08:50.240284Z",
     "shell.execute_reply.started": "2022-04-08T18:08:49.544373Z"
    }
   },
   "outputs": [],
   "source": [
    "n_grams = prepare_text(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:09:13.053555Z",
     "iopub.status.busy": "2022-04-08T18:09:13.05325Z",
     "iopub.status.idle": "2022-04-08T18:09:15.248445Z",
     "shell.execute_reply": "2022-04-08T18:09:15.247651Z",
     "shell.execute_reply.started": "2022-04-08T18:09:13.053519Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = create_data(n_grams, word_id, id_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:09:46.095141Z",
     "iopub.status.busy": "2022-04-08T18:09:46.094829Z",
     "iopub.status.idle": "2022-04-08T18:09:46.103971Z",
     "shell.execute_reply": "2022-04-08T18:09:46.103218Z",
     "shell.execute_reply.started": "2022-04-08T18:09:46.095106Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(list(word_id.keys()))\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:09:37.907932Z",
     "iopub.status.busy": "2022-04-08T18:09:37.907187Z",
     "iopub.status.idle": "2022-04-08T18:09:37.919734Z",
     "shell.execute_reply": "2022-04-08T18:09:37.918958Z",
     "shell.execute_reply.started": "2022-04-08T18:09:37.907872Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:17:50.91365Z",
     "iopub.status.busy": "2022-04-08T18:17:50.912836Z",
     "iopub.status.idle": "2022-04-08T18:17:50.92621Z",
     "shell.execute_reply": "2022-04-08T18:17:50.925295Z",
     "shell.execute_reply.started": "2022-04-08T18:17:50.913588Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.lstm_layers = 4\n",
    "        self.batch_size = 128\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, embedding_size, num_layers=self.lstm_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(4*embedding_size , vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "        hidden = (torch.randn(self.lstm_layers, batch_size, embedding_size).to(device),torch.randn(self.lstm_layers, batch_size, embedding_size).to(device))\n",
    "        x = x.int()\n",
    "        y = self.embedding(x)\n",
    "        out, hidden = self.lstm(y, hidden)\n",
    "        out = out.contiguous()\n",
    "        out = out.view(batch_size,-1)\n",
    "        y = self.fc1(out)\n",
    "        y = F.log_softmax(y, dim = 1)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:11:20.876113Z",
     "iopub.status.busy": "2022-04-08T18:11:20.875807Z",
     "iopub.status.idle": "2022-04-08T18:11:20.888051Z",
     "shell.execute_reply": "2022-04-08T18:11:20.887242Z",
     "shell.execute_reply.started": "2022-04-08T18:11:20.876081Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainvalAdam(model, train_data, valid_data, device, batch_size=128, num_iters=1, learn_rate=0.01):\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True) # shuffle after every epoch\n",
    "    # val_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=0.9)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.90, 0.98), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    # optimizer = optim.Adadelta(model.parameters(),lr=1.0, rho=0.95, eps=1e-08, weight_decay=0.0)\n",
    "    iters, losses, val_losses, train_acc, val_acc = [], [], [], [], []\n",
    "    # training\n",
    "    si = len(train_data)\n",
    "    n = 0 # the number of iterations\n",
    "    for n in tqdm(range(num_iters)):\n",
    "        tot_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            # optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "            out = model(imgs.float())             # forward pass\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "#             print(loss)\n",
    "            tot_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()  # make the updates for each parameter\n",
    "        print('epoch '+str(n)+' = '+str(tot_loss/si))\n",
    "        losses.append(tot_loss/si)   \n",
    "#             if n % 10 == 9:\n",
    "#                 iters.append(n)\n",
    "#                 losses.append(float(loss)/batch_size)        # compute *average* loss\n",
    "# #                 train_accuracy = get_accuracy(model, train_data, device)\n",
    "# #                 val_accuracy = get_accuracy(model, valid_data, device)\n",
    "# #                 print(train_accuracy,val_accuracy)\n",
    "#                 for im, lb in val_loader:\n",
    "#                     im, lb = im.to(device), lb.to(device)\n",
    "#                     val_out = model(im.float())\n",
    "#                     val_loss = criterion(val_out, lb.float())\n",
    "#                 val_losses.append(float(val_loss)/batch_size)\n",
    "                \n",
    "                \n",
    "#                 train_acc.append(train_accuracy) # compute training accuracy \n",
    "#                 val_acc.append(val_accuracy)   # compute validation accuracy\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:11:25.636759Z",
     "iopub.status.busy": "2022-04-08T18:11:25.636498Z",
     "iopub.status.idle": "2022-04-08T18:11:26.49062Z",
     "shell.execute_reply": "2022-04-08T18:11:26.48984Z",
     "shell.execute_reply.started": "2022-04-08T18:11:25.63673Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(x)):\n",
    "  train_data.append((np.array(x[i]),y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:11:30.311959Z",
     "iopub.status.busy": "2022-04-08T18:11:30.311053Z",
     "iopub.status.idle": "2022-04-08T18:11:30.318032Z",
     "shell.execute_reply": "2022-04-08T18:11:30.317218Z",
     "shell.execute_reply.started": "2022-04-08T18:11:30.311907Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:17:56.708553Z",
     "iopub.status.busy": "2022-04-08T18:17:56.708273Z",
     "iopub.status.idle": "2022-04-08T18:27:48.530481Z",
     "shell.execute_reply": "2022-04-08T18:27:48.529738Z",
     "shell.execute_reply.started": "2022-04-08T18:17:56.708523Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "print(model)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(device)\n",
    "model.to(device)\n",
    "train_losses = trainvalAdam(model, train_data, train_data, device, num_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-08T18:28:47.254298Z",
     "iopub.status.busy": "2022-04-08T18:28:47.254022Z",
     "iopub.status.idle": "2022-04-08T18:28:47.27664Z",
     "shell.execute_reply": "2022-04-08T18:28:47.27596Z",
     "shell.execute_reply.started": "2022-04-08T18:28:47.254267Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
