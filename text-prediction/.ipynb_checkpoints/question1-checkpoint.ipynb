{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:15:05.679772Z",
     "iopub.status.busy": "2022-04-11T14:15:05.679011Z",
     "iopub.status.idle": "2022-04-11T14:15:07.065121Z",
     "shell.execute_reply": "2022-04-11T14:15:07.064335Z",
     "shell.execute_reply.started": "2022-04-11T14:15:05.679681Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from nltk import ngrams\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:15:14.761155Z",
     "iopub.status.busy": "2022-04-11T14:15:14.760901Z",
     "iopub.status.idle": "2022-04-11T14:15:14.770557Z",
     "shell.execute_reply": "2022-04-11T14:15:14.769623Z",
     "shell.execute_reply.started": "2022-04-11T14:15:14.761124Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "hashtag_regex = r\"#(\\w+)\"\n",
    "mention_regex = r\"\\B@(?!(?:[a-z0-9.]*_){2})(?!(?:[a-z0-9_]*\\.){2})[._a-z0-9]{3,24}\\b\"\n",
    "start = ['<pad>','<pad>','<pad>','<pad>']\n",
    "# end = np.array(['<pad>','<pad>','<pad>'])\n",
    "punc = [',', '.', '!', ';', '?']\n",
    "def tokenizer(messages):\n",
    "    tokenized_data = []\n",
    "#     for messages in data:\n",
    "    messages = messages.lower()\n",
    "#         messages = re.sub(url_regex,'<URL>',messages)\n",
    "#         messages = re.sub(hashtag_regex,'<HASHTAG>',messages)\n",
    "#         messages = re.sub(mention_regex, '<MENTION>',messages)\n",
    "#         newmessage = ''\n",
    "#         for i in range(len(messages)):\n",
    "#             if re.match(r'[^\\w\\s]', messages[i]) and messages[i]!='<' and messages[i]!='>':\n",
    "#                 newmessage+=' '+messages[i]+' '\n",
    "#             else:\n",
    "#                 newmessage+=messages[i]\n",
    "\n",
    "#         if newmessage == '':\n",
    "#             continue\n",
    "    messages = re.sub(r'[^\\w\\s]','',messages)\n",
    "    words = re.split('\\s|\\t|\\n', messages)\n",
    "#         words = words[words!='']\n",
    "#         if len(words)==0:\n",
    "#             continue\n",
    "#         m = len(words)\n",
    "#         for i  in range(m):\n",
    "#             if len(words[i])!=1:\n",
    "#                 continue\n",
    "#             if words[i] in punc and words[i] not in ['s','e','<URL>','<HASHTAG>','<MENTION>']:\n",
    "#                 words[i] = re.sub(r'[^\\w\\s]','',words[i])\n",
    "#         words = words[words!='']\n",
    "#         for wo in words:\n",
    "#             tokenized_data.append(wo)\n",
    "        #tokenized_data.append(np.concatenate((start, words, end)))\n",
    "    return start+words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:15:23.338245Z",
     "iopub.status.busy": "2022-04-11T14:15:23.337821Z",
     "iopub.status.idle": "2022-04-11T14:15:23.344351Z",
     "shell.execute_reply": "2022-04-11T14:15:23.343407Z",
     "shell.execute_reply.started": "2022-04-11T14:15:23.338210Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus(path):\n",
    "    df = []\n",
    "    si = 0\n",
    "    tot = 0\n",
    "    with open(path) as infile:\n",
    "        for ob in infile:\n",
    "            flag = rand.randint(0,100)\n",
    "            tot+=1\n",
    "            if flag>2:\n",
    "                continue\n",
    "            si+=1\n",
    "            # if si%10000 == 0:\n",
    "            #     print(si,tot)\n",
    "            obj = json.loads(ob)\n",
    "            cur = obj['reviewText']\n",
    "            df.append(tokenizer(cur))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:15:26.070601Z",
     "iopub.status.busy": "2022-04-11T14:15:26.070043Z",
     "iopub.status.idle": "2022-04-11T14:15:26.088245Z",
     "shell.execute_reply": "2022-04-11T14:15:26.087525Z",
     "shell.execute_reply.started": "2022-04-11T14:15:26.070562Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    \"\"\" Function to read input data\n",
    "    Args:\n",
    "        path (string): the parent path of the folder containing the input text files\n",
    "    Returns:\n",
    "        string: The complete text read from input files appended in a single string.\n",
    "    \"\"\"\n",
    "    text = ' '\n",
    "    f = open(path, 'r')\n",
    "    text = f.readlines()\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\" Function for basic cleaning and pre-processing of input text\n",
    "    Args:\n",
    "        text (string): raw input text\n",
    "    Returns:\n",
    "        string: cleaned text\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in text:\n",
    "        data += tokenizer(line)\n",
    "    return data\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r\"'s\\b\", \"\", text)\n",
    "#     text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "#     text = ' '.join([word for word in text.split() if len(word) >= 3]).strip()\n",
    "\n",
    "#     return text\n",
    "\n",
    "\n",
    "def prepare_text(data, n):\n",
    "    \"\"\" Function to prepare text in sequence of ngrams\n",
    "    Args:\n",
    "        text (string): complete input text\n",
    "    Returns:\n",
    "        list : a list of text sequence with 31 characters each\n",
    "    \"\"\"\n",
    "    n_grams = []\n",
    "    for i in range(len(data)-n):\n",
    "        n_grams.append(data[i:i+n])\n",
    "    return n_grams\n",
    "\n",
    "def create_data(data, word_id, id_word):\n",
    "    \"\"\" Function to encode the character sequence into number sequence\n",
    "    Args:\n",
    "        text (string): cleaned text\n",
    "        sequence (list): character sequence list\n",
    "    Returns:\n",
    "        dict: dictionary mapping of all unique input charcters to integers\n",
    "        list: number encoded charachter sequences\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in data:\n",
    "        inp = []\n",
    "        for j in range(4):\n",
    "            if i[j] not in word_id.keys():\n",
    "                inp.append(word_id['<UNKNOWN>'])\n",
    "            else:\n",
    "                inp.append(word_id[i[j]])\n",
    "        if i[4] not in word_id.keys():\n",
    "            y.append(word_id['<UNKNOWN>'])\n",
    "        else:\n",
    "            y.append(word_id[i[4]])\n",
    "        x.append(inp)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x,y\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def split_data(mapping, encoded_sequence):\n",
    "    \"\"\" Function to split the prepared data in train and test\n",
    "    Args:\n",
    "        mapping (dict): dictionary mapping of all unique input charcters to integers\n",
    "        encoded_sequence (list): number encoded charachter sequences\n",
    "    Returns:\n",
    "        numpy array : train and test split numpy arrays\n",
    "    \"\"\"\n",
    "\n",
    "    encoded_sequence_ = np.array(encoded_sequence)\n",
    "    X, y = encoded_sequence_[:, :-1], encoded_sequence_[:, -1]\n",
    "    y = to_categorical(y, num_classes=len(mapping))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def create_vocab(data, threshold =  5):\n",
    "    freq = {}\n",
    "    for i in data:\n",
    "        if i not in freq.keys():\n",
    "            freq[i] = 0\n",
    "        freq[i]+=1\n",
    "    for i in range(len(data)):\n",
    "        if freq[data[i]] <= threshold:\n",
    "            data[i] = '<UNKNOWN>'\n",
    "    word_id = {}\n",
    "    id_word = {}\n",
    "    cur = 0\n",
    "    for i in data:\n",
    "        if i not in word_id.keys():\n",
    "            word_id[i] = cur\n",
    "            id_word[cur] = i\n",
    "            cur+=1\n",
    "    return data, word_id, id_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:15:37.188198Z",
     "iopub.status.busy": "2022-04-11T14:15:37.187942Z",
     "iopub.status.idle": "2022-04-11T14:15:37.247375Z",
     "shell.execute_reply": "2022-04-11T14:15:37.246628Z",
     "shell.execute_reply.started": "2022-04-11T14:15:37.188169Z"
    }
   },
   "outputs": [],
   "source": [
    "text = read_text('../input/dataset/train.europarl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:15:41.688447Z",
     "iopub.status.busy": "2022-04-11T14:15:41.688179Z",
     "iopub.status.idle": "2022-04-11T14:15:42.056423Z",
     "shell.execute_reply": "2022-04-11T14:15:42.055696Z",
     "shell.execute_reply.started": "2022-04-11T14:15:41.688416Z"
    }
   },
   "outputs": [],
   "source": [
    "data = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:15:43.978332Z",
     "iopub.status.busy": "2022-04-11T14:15:43.978087Z",
     "iopub.status.idle": "2022-04-11T14:15:44.311873Z",
     "shell.execute_reply": "2022-04-11T14:15:44.311158Z",
     "shell.execute_reply.started": "2022-04-11T14:15:43.978304Z"
    }
   },
   "outputs": [],
   "source": [
    "data, word_id, id_word = create_vocab(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:01:18.391495Z",
     "iopub.status.busy": "2022-04-09T14:01:18.391226Z",
     "iopub.status.idle": "2022-04-09T14:01:19.121586Z",
     "shell.execute_reply": "2022-04-09T14:01:19.120807Z",
     "shell.execute_reply.started": "2022-04-09T14:01:18.391464Z"
    }
   },
   "outputs": [],
   "source": [
    "n_grams = prepare_text(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:01:22.264653Z",
     "iopub.status.busy": "2022-04-09T14:01:22.264126Z",
     "iopub.status.idle": "2022-04-09T14:01:24.846848Z",
     "shell.execute_reply": "2022-04-09T14:01:24.846064Z",
     "shell.execute_reply.started": "2022-04-09T14:01:22.264615Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = create_data(n_grams, word_id, id_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:16:04.679416Z",
     "iopub.status.busy": "2022-04-11T14:16:04.679107Z",
     "iopub.status.idle": "2022-04-11T14:16:04.684131Z",
     "shell.execute_reply": "2022-04-11T14:16:04.683442Z",
     "shell.execute_reply.started": "2022-04-11T14:16:04.679380Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(list(word_id.keys()))\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:16:10.023119Z",
     "iopub.status.busy": "2022-04-11T14:16:10.022837Z",
     "iopub.status.idle": "2022-04-11T14:16:12.055054Z",
     "shell.execute_reply": "2022-04-11T14:16:12.054364Z",
     "shell.execute_reply.started": "2022-04-11T14:16:10.023089Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:16:14.484597Z",
     "iopub.status.busy": "2022-04-11T14:16:14.484311Z",
     "iopub.status.idle": "2022-04-11T14:16:14.492933Z",
     "shell.execute_reply": "2022-04-11T14:16:14.492124Z",
     "shell.execute_reply.started": "2022-04-11T14:16:14.484565Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.lstm_layers = 4\n",
    "        self.batch_size = 128\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, embedding_size, num_layers=self.lstm_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(4*embedding_size , vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "        hidden = (torch.randn(self.lstm_layers, batch_size, embedding_size).to(device),torch.randn(self.lstm_layers, batch_size, embedding_size).to(device))\n",
    "        x = x.int()\n",
    "        y = self.embedding(x)\n",
    "        out, hidden = self.lstm(y, hidden)\n",
    "        out = out.contiguous()\n",
    "        out = out.view(batch_size,-1)\n",
    "        y = self.fc1(out)\n",
    "        y = F.softmax(y, dim = 1)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:16:19.219558Z",
     "iopub.status.busy": "2022-04-11T14:16:19.219274Z",
     "iopub.status.idle": "2022-04-11T14:16:19.229016Z",
     "shell.execute_reply": "2022-04-11T14:16:19.228348Z",
     "shell.execute_reply.started": "2022-04-11T14:16:19.219526Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainvalAdam(model, train_data, valid_data, device, batch_size=128, num_iters=1, learn_rate=0.01):\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True) # shuffle after every epoch\n",
    "    # val_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=0.9)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.90, 0.98), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    # optimizer = optim.Adadelta(model.parameters(),lr=1.0, rho=0.95, eps=1e-08, weight_decay=0.0)\n",
    "    iters, losses, val_losses, train_acc, val_acc = [], [], [], [], []\n",
    "    # training\n",
    "    si = len(train_data)\n",
    "    n = 0 # the number of iterations\n",
    "    for n in tqdm(range(num_iters)):\n",
    "        tot_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            # optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "            out = model(imgs.float())             # forward pass\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "#             print(loss)\n",
    "            tot_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()  # make the updates for each parameter\n",
    "        print('epoch '+str(n)+' = '+str(tot_loss/si))\n",
    "        losses.append(tot_loss/si)   \n",
    "#             if n % 10 == 9:\n",
    "#                 iters.append(n)\n",
    "#                 losses.append(float(loss)/batch_size)        # compute *average* loss\n",
    "# #                 train_accuracy = get_accuracy(model, train_data, device)\n",
    "# #                 val_accuracy = get_accuracy(model, valid_data, device)\n",
    "# #                 print(train_accuracy,val_accuracy)\n",
    "#                 for im, lb in val_loader:\n",
    "#                     im, lb = im.to(device), lb.to(device)\n",
    "#                     val_out = model(im.float())\n",
    "#                     val_loss = criterion(val_out, lb.float())\n",
    "#                 val_losses.append(float(val_loss)/batch_size)\n",
    "                \n",
    "                \n",
    "#                 train_acc.append(train_accuracy) # compute training accuracy \n",
    "#                 val_acc.append(val_accuracy)   # compute validation accuracy\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:01:51.617723Z",
     "iopub.status.busy": "2022-04-09T14:01:51.616923Z",
     "iopub.status.idle": "2022-04-09T14:01:52.723113Z",
     "shell.execute_reply": "2022-04-09T14:01:52.72235Z",
     "shell.execute_reply.started": "2022-04-09T14:01:51.617665Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(x)):\n",
    "  if y[i]==word_id['<pad>']:\n",
    "    continue\n",
    "  train_data.append((np.array(x[i]),y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:07:01.643709Z",
     "iopub.status.busy": "2022-04-09T14:07:01.642935Z",
     "iopub.status.idle": "2022-04-09T14:14:25.470037Z",
     "shell.execute_reply": "2022-04-09T14:14:25.469252Z",
     "shell.execute_reply.started": "2022-04-09T14:07:01.643638Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Classifier()\n",
    "# print(model)\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# # device = \"cpu\"\n",
    "# print(device)\n",
    "# model.to(device)\n",
    "# train_losses = trainvalAdam(model, train_data, train_data, device, num_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:14:37.635644Z",
     "iopub.status.busy": "2022-04-09T14:14:37.635379Z",
     "iopub.status.idle": "2022-04-09T14:14:37.652488Z",
     "shell.execute_reply": "2022-04-09T14:14:37.651712Z",
     "shell.execute_reply.started": "2022-04-09T14:14:37.635615Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(),'./model-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:23:21.259663Z",
     "iopub.status.busy": "2022-04-11T14:23:21.259002Z",
     "iopub.status.idle": "2022-04-11T14:23:21.441105Z",
     "shell.execute_reply": "2022-04-11T14:23:21.440431Z",
     "shell.execute_reply.started": "2022-04-11T14:23:21.259625Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./models/model-4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:27:42.508487Z",
     "iopub.status.busy": "2022-04-11T14:27:42.508211Z",
     "iopub.status.idle": "2022-04-11T14:27:42.519305Z",
     "shell.execute_reply": "2022-04-11T14:27:42.518541Z",
     "shell.execute_reply.started": "2022-04-11T14:27:42.508442Z"
    }
   },
   "outputs": [],
   "source": [
    "def perplexity(train_data):\n",
    "  acc = 0.0\n",
    "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False) # shuffle after every epoch\n",
    "  probab = []\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    pro = 1.0\n",
    "    le = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        if imgs[0][-1] == word_id['<pad>']:\n",
    "#         print('Hello ',pro,le)\n",
    "            if pro==0:\n",
    "                pro = np.random.uniform(1e-9,1e-8)\n",
    "            per = (1/(pro+1e-10))**(1/(le+4))\n",
    "            probab.append(per)\n",
    "            pro = 1.0\n",
    "            le = 0\n",
    "        out = model(imgs.float().to(device))\n",
    "        pro*=out[0][labels[0]]\n",
    "        le+=1\n",
    "  if pro==0:\n",
    "      pro = np.random.uniform(1e-9,1e-8)\n",
    "  per = (1/(pro+1e-10))**(1/(le+4))\n",
    "  probab.append(per)\n",
    "  return probab\n",
    "\n",
    "# per = perplexity(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:24:47.072426Z",
     "iopub.status.busy": "2022-04-09T14:24:47.071603Z",
     "iopub.status.idle": "2022-04-09T14:24:47.08064Z",
     "shell.execute_reply": "2022-04-09T14:24:47.079812Z",
     "shell.execute_reply.started": "2022-04-09T14:24:47.072384Z"
    }
   },
   "outputs": [],
   "source": [
    "# def avgPer(per):\n",
    "#     sum = 0\n",
    "#     for i in per:\n",
    "#         sum += float(i)\n",
    "#     sum/=len(per)\n",
    "#     return sum\n",
    "\n",
    "# avg_train_per = avgPer(per)\n",
    "# print(avg_train_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:25:41.181793Z",
     "iopub.status.busy": "2022-04-09T14:25:41.181028Z",
     "iopub.status.idle": "2022-04-09T14:25:41.228976Z",
     "shell.execute_reply": "2022-04-09T14:25:41.228313Z",
     "shell.execute_reply.started": "2022-04-09T14:25:41.181756Z"
    }
   },
   "outputs": [],
   "source": [
    "# f = open('train-europarl-lm.txt','w')\n",
    "# f.write('Average perplexity = '+str(avg_train_per)+'\\n')\n",
    "# for i in range(len(text)):\n",
    "#     f.write(text[i]+'     '+str(float(per[i]))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T14:29:42.299064Z",
     "iopub.status.busy": "2022-04-11T14:29:42.298492Z",
     "iopub.status.idle": "2022-04-11T14:29:42.318992Z",
     "shell.execute_reply": "2022-04-11T14:29:42.318344Z",
     "shell.execute_reply.started": "2022-04-11T14:29:42.299026Z"
    }
   },
   "outputs": [],
   "source": [
    "# f = open('test-europarl-lm.txt','w')\n",
    "# f.write('Average perplexity = '+str(avg_train_per)+'\\n')\n",
    "# for i in range(len(text_test)):\n",
    "#     f.write(text_test[i]+'     '+str(float(per[i]))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = input(\"Enter the sentence : \\n\")\n",
    "text_test = [sent]\n",
    "data_test = preprocess_text(text_test)\n",
    "n_grams_test = prepare_text(data_test, 5)\n",
    "test_x, test_y = create_data(n_grams_test, word_id, id_word)\n",
    "test_data = []\n",
    "for i in range(len(test_x)):\n",
    "  test_data.append((np.array(test_x[i]),test_y[i]))\n",
    "\n",
    "per = perplexity(test_data)\n",
    "def avgPer(per):\n",
    "    sum = 0\n",
    "    for i in per:\n",
    "        sum += float(i)\n",
    "    sum/=len(per)\n",
    "    return sum\n",
    "\n",
    "avg_train_per = avgPer(per)\n",
    "print('The perplexity is : ' , avg_train_per)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
